export interface AgentsVoiceConfig {
  instructions: string;
  voice?: string;
  model?: string;
  onSessionReady?: () => void;
  onSpeechStarted?: () => void;
  onSpeechStopped?: () => void;
  onResponseStarted?: () => void;
  onResponseCompleted?: (text: string) => void;
  onError?: (error: string) => void;
  onInterruption?: () => void;
}

export class AgentsVoiceService {
  private pc: RTCPeerConnection | null = null;
  private dc: RTCDataChannel | null = null;
  private audioEl: HTMLAudioElement | null = null;
  private stream: MediaStream | null = null;
  private config: AgentsVoiceConfig;
  private isConnected = false;
  private isRecording = false;

  constructor(config: AgentsVoiceConfig) {
    this.config = config;
  }

  async connect(): Promise<void> {
    try {
      console.log('üöÄ Initialisation Agent SDK WebRTC Direct...');

      // 1. G√©n√©rer token √©ph√©m√®re via OpenAI directement (plus besoin d'Edge Function)
      let OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY;
      
      // Fallback vers localStorage si pas dans .env
      if (!OPENAI_API_KEY || OPENAI_API_KEY === '' || OPENAI_API_KEY === 'sk-...') {
        OPENAI_API_KEY = localStorage.getItem('openai_api_key');
      }
      
      if (!OPENAI_API_KEY || !OPENAI_API_KEY.startsWith('sk-')) {
        throw new Error('VITE_OPENAI_API_KEY requis pour Agent SDK');
      }

      const response = await fetch("https://api.openai.com/v1/realtime/client_secrets", {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          session: {
            type: "realtime",
            model: this.config.model || "gpt-realtime",
            voice: this.config.voice || "sage",
            instructions: this.config.instructions,
            modalities: ["text", "audio"],
            input_audio_format: "pcm16",
            output_audio_format: "pcm16",
            input_audio_transcription: {
              model: "whisper-1"
            },
            turn_detection: {
              type: "server_vad",
              threshold: 0.5,
              prefix_padding_ms: 300,
              silence_duration_ms: 1000
            },
            temperature: 0.8
          }
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Token generation failed: ${response.status} ${errorText}`);
      }

      const data = await response.json();
      const ephemeralKey = data.client_secret.value;
      console.log('‚úÖ Token √©ph√©m√®re g√©n√©r√©');

      // 2. Configuration WebRTC
      this.pc = new RTCPeerConnection();
      this.audioEl = document.createElement("audio");
      this.audioEl.autoplay = true;

      // 3. Gestion audio distant (r√©ponses IA)
      this.pc.ontrack = (e) => {
        if (this.audioEl) {
          this.audioEl.srcObject = e.streams[0];
          console.log('üîä Audio IA connect√©');
        }
      };

      // 4. Capture microphone utilisateur
      this.stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 24000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      this.pc.addTrack(this.stream.getTracks()[0]);
      console.log('üé§ Microphone connect√©');

      // 5. Data Channel pour √©v√©nements
      this.dc = this.pc.createDataChannel("oai-events");
      this.setupDataChannelHandlers();

      // 6. N√©gociation WebRTC
      const offer = await this.pc.createOffer();
      await this.pc.setLocalDescription(offer);

      // 7. Connexion √† OpenAI Realtime API
      const baseUrl = "https://api.openai.com/v1/realtime";
      const modelParam = this.config.model || "gpt-realtime";
      
      const sdpResponse = await fetch(`${baseUrl}?model=${modelParam}`, {
        method: "POST",
        body: offer.sdp,
        headers: {
          Authorization: `Bearer ${ephemeralKey}`,
          "Content-Type": "application/sdp"
        },
      });

      if (!sdpResponse.ok) {
        throw new Error(`WebRTC negotiation failed: ${sdpResponse.status}`);
      }

      const answer = {
        type: "answer" as RTCSdpType,
        sdp: await sdpResponse.text(),
      };
      
      await this.pc.setRemoteDescription(answer);

      this.isConnected = true;
      console.log('üéØ Agent SDK WebRTC connect√© avec succ√®s');
      this.config.onSessionReady?.();

    } catch (error: any) {
      console.error('‚ùå Erreur connexion Agent SDK:', error);
      this.config.onError?.(error.message || 'Connection failed');
      throw error;
    }
  }

  private setupDataChannelHandlers(): void {
    if (!this.dc) return;

    this.dc.addEventListener("open", () => {
      console.log('üì° Data channel ouvert');
    });

    this.dc.addEventListener("message", (e) => {
      try {
        const event = JSON.parse(e.data);
        this.handleRealtimeEvent(event);
      } catch (error) {
        console.error('‚ùå Erreur parsing √©v√©nement:', error);
      }
    });

    this.dc.addEventListener("error", (error) => {
      console.error('‚ùå Erreur data channel:', error);
      this.config.onError?.('Data channel error');
    });
  }

  private handleRealtimeEvent(event: any): void {
    console.log('üì® √âv√©nement re√ßu:', event.type);

    switch (event.type) {
      case 'input_audio_buffer.speech_started':
        this.config.onSpeechStarted?.();
        break;
      
      case 'input_audio_buffer.speech_stopped':
        this.config.onSpeechStopped?.();
        break;
      
      case 'response.audio.delta':
        this.config.onResponseStarted?.();
        break;
      
      case 'response.audio.done':
        this.config.onResponseCompleted?.('Response completed');
        break;
      
      case 'response.audio_transcript.delta':
        if (event.delta) {
          console.log('üìù Transcription:', event.delta);
        }
        break;
      
      case 'response.audio_transcript.done':
        if (event.transcript) {
          console.log('üìÑ Transcription compl√®te:', event.transcript);
          this.config.onResponseCompleted?.(event.transcript);
        }
        break;
      
      case 'conversation.item.input_audio_transcription.completed':
        console.log('üë§ Utilisateur:', event.transcript);
        break;
      
      case 'error':
        console.error('‚ùå Erreur √©v√©nement:', event);
        this.config.onError?.(event.error?.message || 'Event error');
        break;
      
      default:
        console.log('üì¶ √âv√©nement non g√©r√©:', event.type);
    }
  }

  async sendMessage(text: string): Promise<void> {
    if (!this.dc || this.dc.readyState !== 'open') {
      throw new Error('Data channel not ready');
    }

    try {
      console.log('üì§ Envoi message:', text);
      
      const event = {
        type: 'conversation.item.create',
        item: {
          type: 'message',
          role: 'user',
          content: [
            {
              type: 'input_text',
              text
            }
          ]
        }
      };

      this.dc.send(JSON.stringify(event));
      this.dc.send(JSON.stringify({type: 'response.create'}));
      
    } catch (error: any) {
      console.error('‚ùå Erreur envoi message:', error);
      this.config.onError?.(error.message || 'Send message failed');
    }
  }

  async interrupt(): Promise<void> {
    if (!this.dc || this.dc.readyState !== 'open') return;

    try {
      console.log('‚ö° Interruption demand√©e');
      
      const event = {
        type: 'response.cancel'
      };

      this.dc.send(JSON.stringify(event));
      this.config.onInterruption?.();
      
    } catch (error: any) {
      console.error('‚ùå Erreur interruption:', error);
    }
  }

  disconnect(): void {
    try {
      console.log('üîå D√©connexion Agent SDK...');
      
      if (this.stream) {
        this.stream.getTracks().forEach(track => track.stop());
        this.stream = null;
      }
      
      if (this.dc) {
        this.dc.close();
        this.dc = null;
      }
      
      if (this.pc) {
        this.pc.close();
        this.pc = null;
      }
      
      if (this.audioEl) {
        this.audioEl.srcObject = null;
        this.audioEl = null;
      }
      
      this.isConnected = false;
      console.log('‚úÖ Agent SDK d√©connect√©');
    } catch (error: any) {
      console.error('‚ùå Erreur d√©connexion:', error);
    }
  }

  getConnectionStatus(): boolean {
    return this.isConnected;
  }

  // M√©thodes avanc√©es
  async setInstructions(instructions: string): Promise<void> {
    if (!this.dc || this.dc.readyState !== 'open') return;

    try {
      console.log('üìù Instructions mises √† jour');
      
      const event = {
        type: 'session.update',
        session: {
          instructions: instructions
        }
      };

      this.dc.send(JSON.stringify(event));
    } catch (error: any) {
      console.error('‚ùå Erreur mise √† jour instructions:', error);
    }
  }

  async setVoice(voice: string): Promise<void> {
    if (!this.dc || this.dc.readyState !== 'open') return;

    try {
      console.log('üéôÔ∏è Voix mise √† jour:', voice);
      
      const event = {
        type: 'session.update',
        session: {
          voice: voice
        }
      };

      this.dc.send(JSON.stringify(event));
    } catch (error: any) {
      console.error('‚ùå Erreur mise √† jour voix:', error);
    }
  }

  // Optimisations co√ªt GA
  async enableCachedInput(): Promise<void> {
    if (!this.dc || this.dc.readyState !== 'open') return;

    try {
      console.log('üí∞ Optimisations de co√ªt activ√©es');
      
      const event = {
        type: 'session.update',
        session: {
          max_response_output_tokens: 4000,
          temperature: 0.8,
        }
      };

      this.dc.send(JSON.stringify(event));
    } catch (error: any) {
      console.error('‚ùå Erreur activation cache:', error);
    }
  }

  // Nouvelles fonctionnalit√©s GA
  async enableAdvancedFeatures(): Promise<void> {
    if (!this.dc || this.dc.readyState !== 'open') return;

    try {
      console.log('üî• Fonctionnalit√©s avanc√©es GA activ√©es');
      
      const event = {
        type: 'session.update',
        session: {
          turn_detection: {
            type: 'server_vad',
            threshold: 0.5,
            prefix_padding_ms: 300,
            silence_duration_ms: 1000
          },
          input_audio_transcription: {
            model: 'whisper-1'
          }
        }
      };

      this.dc.send(JSON.stringify(event));
    } catch (error: any) {
      console.error('‚ùå Erreur fonctionnalit√©s avanc√©es:', error);
    }
  }
}