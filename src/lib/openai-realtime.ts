// Configuration optimis√©e pour l'API Realtime d'OpenAI selon guide prompting
export const REALTIME_CONFIG = {
  model: "gpt-realtime-2025-08-28",
  voice: "sage", // Voix professionnelle et claire pour contexte business
  baseUrl: "https://api.openai.com/v1/realtime",
  wsUrl: "wss://api.openai.com/v1/realtime",
  
  // Configuration session optimis√©e selon OpenAI Realtime Guide
  sessionConfig: {
    modalities: ["text", "audio"],
    input_audio_format: "pcm16",
    output_audio_format: "pcm16",
    input_audio_transcription: {
      model: "whisper-1"
    },
    turn_detection: {
      type: "server_vad", // TOUJOURS utiliser server_vad
      threshold: 0.5, // Ajust√© selon contexte conversation
      prefix_padding_ms: 300,
      silence_duration_ms: 1000 // Ajust√© selon type conversation
    },
    temperature: 0.7, // √âquilibre cr√©ativit√©/consistance pour vocal
    max_response_output_tokens: "inf"
  }
};

// Types pour les √©v√©nements Realtime
export interface RealtimeEvent {
  type: string;
  [key: string]: any;
}

export interface SessionConfig {
  model: string;
  voice: string;
  instructions?: string;
  modalities?: string[];
  temperature?: number;
  turn_detection?: {
    type: string;
    threshold?: number;
    prefix_padding_ms?: number;
    silence_duration_ms?: number;
  } | null;
}

// Classe pour g√©rer la connexion Realtime API
export class RealtimeVoiceCoach {
  private ws: WebSocket | null = null;
  private audioContext: AudioContext | null = null;
  private mediaRecorder: MediaRecorder | null = null;
  private optimizedAudioQueue: any = null;
  private isConnected = false;
  private isRecording = false;

  constructor(private apiKey: string) {}

  // Cr√©er une session √©ph√©m√®re pour les connexions client
  async createEphemeralSession(): Promise<any> {
    const response = await fetch("https://api.openai.com/v1/realtime/sessions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${this.apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: REALTIME_CONFIG.model,
        voice: REALTIME_CONFIG.voice,
      }),
    });

    if (!response.ok) {
      throw new Error(`Erreur lors de la cr√©ation de la session: ${response.status}`);
    }

    return response.json();
  }

  // Connexion WebSocket avec l'API Realtime
  async connect(instructions?: string): Promise<void> {
    try {
      const url = `${REALTIME_CONFIG.wsUrl}?model=${REALTIME_CONFIG.model}`;
      
      this.ws = new WebSocket(url, [
        "realtime",
        `openai-insecure-api-key.${this.apiKey}`,
        "openai-beta.realtime-v1"
      ]);

      this.ws.onopen = () => {
        console.log("Connexion WebSocket √©tablie");
        this.isConnected = true;
        this.initializeSession(instructions);
      };

      this.ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        this.handleServerEvent(data);
      };

      this.ws.onerror = (error) => {
        console.error("Erreur WebSocket:", error);
        this.isConnected = false;
      };

      this.ws.onclose = () => {
        console.log("Connexion WebSocket ferm√©e");
        this.isConnected = false;
      };

      // Initialiser le contexte audio
      this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();

    } catch (error) {
      console.error("Erreur de connexion:", error);
      throw error;
    }
  }

  // PHASE 2: Configuration Session Optimis√©e - Session.update APR√àS session.created
  private sessionInstructions: string | null = null;
  private sessionReady = false;

  private initializeSession(instructions?: string): void {
    this.sessionInstructions = instructions || SALES_COACH_PROMPT;
    // Attendre session.created avant d'envoyer session.update
  }

  private sendSessionUpdate(): void {
    if (!this.ws || !this.sessionInstructions) return;

    console.log("üì° Envoi session.update apr√®s session.created");
    
    const sessionConfig = {
      modalities: ["text", "audio"],
      instructions: this.sessionInstructions,
      input_audio_format: "pcm16",
      output_audio_format: "pcm16", 
      input_audio_transcription: {
        model: "whisper-1"
      },
      turn_detection: {
        type: "server_vad",
        threshold: 0.5,
        prefix_padding_ms: 300,
        silence_duration_ms: 1000  // Augment√© pour √©viter coupures
      },
      temperature: 0.7,
      max_response_output_tokens: "inf"
    };

    this.sendEvent({
      type: "session.update",
      session: sessionConfig,
    });
  }

  // Envoyer un √©v√©nement au serveur
  private sendEvent(event: RealtimeEvent): void {
    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(JSON.stringify(event));
    }
  }

  // G√©rer les √©v√©nements du serveur
  private handleServerEvent(event: RealtimeEvent): void {
    console.log("√âv√©nement re√ßu:", event.type, event);

    switch (event.type) {
      case "session.created":
        console.log("‚úÖ Session cr√©√©e avec succ√®s");
        this.sessionReady = true;
        // CRITIQUE: Envoyer session.update APR√àS session.created
        this.sendSessionUpdate();
        break;

      case "session.updated":
        console.log("‚úÖ Session mise √† jour avec configuration optimis√©e");
        break;

      case "input_audio_buffer.speech_started":
        console.log("D√©tection de parole utilisateur");
        this.onSpeechStarted?.();
        break;

      case "input_audio_buffer.speech_stopped":
        console.log("Fin de parole utilisateur");
        this.onSpeechStopped?.();
        break;

      case "response.created":
        console.log("R√©ponse en cours de g√©n√©ration");
        this.onResponseStarted?.();
        break;

      case "response.audio.delta":
        this.handleAudioDelta(event.delta);
        break;

      case "response.audio_transcript.delta":
        this.onTranscriptDelta?.(event.delta);
        break;

      case "response.done":
        console.log("R√©ponse termin√©e");
        this.onResponseCompleted?.(event.response);
        break;

      case "error":
        console.error("Erreur serveur:", event.error);
        this.onError?.(event.error);
        break;
    }
  }

  // PHASE 1: Architecture Audio Critique - Gestion correcte des chunks audio
  // G√©rer les chunks audio re√ßus avec queue s√©quentielle
  private async handleAudioDelta(audioData: string): Promise<void> {
    if (!this.audioContext) return;

    try {
      // D√©coder le base64 en Uint8Array (PCM16)
      const binaryString = atob(audioData);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }

      // Initialiser la queue audio si n√©cessaire
      if (!this.optimizedAudioQueue) {
        const { AudioQueue } = await import('./audio/AudioQueue');
        this.optimizedAudioQueue = new AudioQueue(this.audioContext);
      }

      // Ajouter √† la queue pour lecture s√©quentielle
      await this.optimizedAudioQueue.addToQueue(bytes);
      
    } catch (error) {
      console.error("‚ùå Erreur d√©codage audio PCM16:", error);
    }
  }

  // D√©marrer l'enregistrement audio
  async startRecording(): Promise<void> {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 24000,
        }
      });

      this.mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm;codecs=opus'
      });

      const audioChunks: BlobPart[] = [];

      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunks.push(event.data);
          this.processAudioChunk(event.data);
        }
      };

      this.mediaRecorder.start(100); // Chunks de 100ms
      this.isRecording = true;
      console.log("Enregistrement d√©marr√©");

    } catch (error) {
      console.error("Erreur d√©marrage enregistrement:", error);
      throw error;
    }
  }

  // PHASE 1: Traitement audio optimis√© avec encodage PCM16 correct
  private async processAudioChunk(chunk: Blob): Promise<void> {
    if (!this.ws || !this.isConnected || !this.sessionReady) return;

    try {
      const arrayBuffer = await chunk.arrayBuffer();
      
      // Utiliser l'encodeur audio optimis√©
      const { encodeAudioForAPI } = await import('./audio/AudioRecorder');
      const float32Data = new Float32Array(arrayBuffer);
      const base64Audio = encodeAudioForAPI(float32Data);

      this.sendEvent({
        type: "input_audio_buffer.append",
        audio: base64Audio,
      });
    } catch (error) {
      console.error("‚ùå Erreur traitement audio chunk:", error);
    }
  }

  // Arr√™ter l'enregistrement
  stopRecording(): void {
    if (this.mediaRecorder && this.isRecording) {
      this.mediaRecorder.stop();
      this.isRecording = false;
      console.log("Enregistrement arr√™t√©");

      // Valider le buffer audio
      this.sendEvent({
        type: "input_audio_buffer.commit",
      });
    }
  }

  // Envoyer un message texte
  sendTextMessage(text: string): void {
    this.sendEvent({
      type: "conversation.item.create",
      item: {
        type: "message",
        role: "user",
        content: [
          {
            type: "input_text",
            text: text,
          },
        ],
      },
    });

    // Cr√©er une r√©ponse
    this.sendEvent({
      type: "response.create",
    });
  }

  // Interrompre la r√©ponse en cours
  cancelResponse(): void {
    this.sendEvent({
      type: "response.cancel",
    });
  }

  // D√©connecter
  disconnect(): void {
    if (this.mediaRecorder) {
      this.mediaRecorder.stop();
    }
    
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }

    if (this.audioContext) {
      this.audioContext.close();
      this.audioContext = null;
    }

    this.isConnected = false;
    this.isRecording = false;
  }

  // Callbacks pour les √©v√©nements
  onSpeechStarted?: () => void;
  onSpeechStopped?: () => void;
  onResponseStarted?: () => void;
  onResponseCompleted?: (response: any) => void;
  onTranscriptDelta?: (delta: string) => void;
  onError?: (error: any) => void;
}

// PHASE 3: PROMPT VOCAL OPTIMIS√â selon OpenAI Realtime Guide
export const SALES_COACH_PROMPT = `# Role & Objective
Coach commercial expert sp√©cialis√© formation vente B2B tech interactive.
SUCC√àS = Aider utilisateur am√©liorer comp√©tences commerciales via feedback temps r√©el.

# Personality & Tone
## Personality
- Expert bienveillant avec 15+ ans exp√©rience
- Patient, encourageant, constructif dans retours
## Tone
- Professionnel, naturel, jamais condescendant
## Length
2-3 phrases courtes par intervention.
## Language
- Conversation uniquement en fran√ßais
- Pas de changement langue m√™me si demand√©
## Variety
- Variez vos encouragements: "Excellent", "Tr√®s bien", "Parfait", "Bien jou√©"
- Alternez structure conseils pour √©viter r√©p√©tition

# Instructions/Rules
## Domaines Expertise
- Techniques vente et n√©gociation B2B
- Prospection qualifi√©e secteur tech
- Pr√©sentation commerciale data-driven
- Gestion objections techniques/budget/timing
- Closing et steps suivants concrets

## Coaching Approach
- Posez questions courtes pour comprendre contexte
- Conseils actionnables imm√©diatement applicables
- Exemples concrets secteur/situation utilisateur
- Feedback positif + 1 point am√©lioration max

# Sample Phrases
Variez ces exemples, ne r√©p√©tez pas:
## Encouragements
- "Excellente approche, continuez comme √ßa"
- "Tr√®s bien, vous adaptez votre discours"
- "Parfait, vous √©coutez vraiment le prospect"

## Conseils courts
- "Creusez davantage l'impact business"
- "Posez une question ouverte maintenant"  
- "Reformulez pour confirmer la compr√©hension"

## Questions coaching
- "Quel √©tait votre objectif cette phase?"
- "Comment le prospect a-t-il r√©agi?"
- "Que feriez-vous diff√©remment?"`;

// Fonction utilitaire pour g√©rer les erreurs
export function handleRealtimeError(error: any): string {
  console.error("Erreur Realtime API:", error);
  
  if (error.type === "authentication_error") {
    return "Erreur d'authentification. V√©rifiez votre cl√© API.";
  } else if (error.type === "rate_limit_error") {
    return "Limite de d√©bit atteinte. Veuillez r√©essayer plus tard.";
  } else if (error.type === "connection_error") {
    return "Erreur de connexion. V√©rifiez votre connexion internet.";
  } else {
    return "Une erreur inattendue s'est produite. Veuillez r√©essayer.";
  }
}